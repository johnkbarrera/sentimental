{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install mysql\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>idUsuario</th>\n",
       "      <th>fechaCreacion</th>\n",
       "      <th>texto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1062491062751686656</td>\n",
       "      <td>226802593</td>\n",
       "      <td>2018-11-13 23:43:04</td>\n",
       "      <td>Como cuando ahora también tiene que prepararte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1062491070980935682</td>\n",
       "      <td>1020688128250646528</td>\n",
       "      <td>2018-11-13 23:43:06</td>\n",
       "      <td>Sres. @AsambleaEcuador no arriesguen más la sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1062491474594476039</td>\n",
       "      <td>353815647</td>\n",
       "      <td>2018-11-13 23:44:42</td>\n",
       "      <td>Comencemos esta experiencia!! #psicologosenelm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1062491477002084352</td>\n",
       "      <td>561395391</td>\n",
       "      <td>2018-11-13 23:44:42</td>\n",
       "      <td>@galarzaramiro1 @AdrianPalacioJ @VillaFernando...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id            idUsuario       fechaCreacion  \\\n",
       "0  1062491062751686656            226802593 2018-11-13 23:43:04   \n",
       "1  1062491070980935682  1020688128250646528 2018-11-13 23:43:06   \n",
       "2  1062491474594476039            353815647 2018-11-13 23:44:42   \n",
       "3  1062491477002084352            561395391 2018-11-13 23:44:42   \n",
       "\n",
       "                                               texto  \n",
       "0  Como cuando ahora también tiene que prepararte...  \n",
       "1  Sres. @AsambleaEcuador no arriesguen más la sa...  \n",
       "2  Comencemos esta experiencia!! #psicologosenelm...  \n",
       "3  @galarzaramiro1 @AdrianPalacioJ @VillaFernando...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pymysql\n",
    "\n",
    "tweetSchema= {'fechaCreacion': {'format': '%Y-%m-%d %H:%M:%S'}}\n",
    "\n",
    "myconnection = pymysql.connect(host = 'localhost', user = 'root',password = 'root',db = 'dbtwitter', charset='utf8')\n",
    "\n",
    "data_db = None\n",
    "try:\n",
    "    query = \"\"\"SELECT * FROM tweet\"\"\"\n",
    "    data_db = pd.read_sql(query, con = myconnection, parse_dates = tweetSchema)\n",
    "finally:\n",
    "    myconnection.close()\n",
    "\n",
    "data_db.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweet_texto = data_db[\"texto\"]\n",
    "# df_tweet_texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "# nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['de', 'la', 'que', 'el', 'en', 'y', 'a', 'los', 'del', 'se', 'las', 'por', 'un', 'para', 'con', 'no', 'una', 'su', 'al', 'lo', 'como', 'más', 'pero', 'sus', 'le', 'ya', 'o', 'este', 'sí', 'porque', 'esta', 'entre', 'cuando', 'muy', 'sin', 'sobre', 'también', 'me', 'hasta', 'hay', 'donde', 'quien', 'desde', 'todo', 'nos', 'durante', 'todos', 'uno', 'les', 'ni', 'contra', 'otros', 'ese', 'eso', 'ante', 'ellos', 'e', 'esto', 'mí', 'antes', 'algunos', 'qué', 'unos', 'yo', 'otro', 'otras', 'otra', 'él', 'tanto', 'esa', 'estos', 'mucho', 'quienes', 'nada', 'muchos', 'cual', 'poco', 'ella', 'estar', 'estas', 'algunas', 'algo', 'nosotros', 'mi', 'mis', 'tú', 'te', 'ti', 'tu', 'tus', 'ellas', 'nosotras', 'vosostros', 'vosostras', 'os', 'mío', 'mía', 'míos', 'mías', 'tuyo', 'tuya', 'tuyos', 'tuyas', 'suyo', 'suya', 'suyos', 'suyas', 'nuestro', 'nuestra', 'nuestros', 'nuestras', 'vuestro', 'vuestra', 'vuestros', 'vuestras', 'esos', 'esas', 'estoy', 'estás', 'está', 'estamos', 'estáis', 'están', 'esté', 'estés', 'estemos', 'estéis', 'estén', 'estaré', 'estarás', 'estará', 'estaremos', 'estaréis', 'estarán', 'estaría', 'estarías', 'estaríamos', 'estaríais', 'estarían', 'estaba', 'estabas', 'estábamos', 'estabais', 'estaban', 'estuve', 'estuviste', 'estuvo', 'estuvimos', 'estuvisteis', 'estuvieron', 'estuviera', 'estuvieras', 'estuviéramos', 'estuvierais', 'estuvieran', 'estuviese', 'estuvieses', 'estuviésemos', 'estuvieseis', 'estuviesen', 'estando', 'estado', 'estada', 'estados', 'estadas', 'estad', 'he', 'has', 'ha', 'hemos', 'habéis', 'han', 'haya', 'hayas', 'hayamos', 'hayáis', 'hayan', 'habré', 'habrás', 'habrá', 'habremos', 'habréis', 'habrán', 'habría', 'habrías', 'habríamos', 'habríais', 'habrían', 'había', 'habías', 'habíamos', 'habíais', 'habían', 'hube', 'hubiste', 'hubo', 'hubimos', 'hubisteis', 'hubieron', 'hubiera', 'hubieras', 'hubiéramos', 'hubierais', 'hubieran', 'hubiese', 'hubieses', 'hubiésemos', 'hubieseis', 'hubiesen', 'habiendo', 'habido', 'habida', 'habidos', 'habidas', 'soy', 'eres', 'es', 'somos', 'sois', 'son', 'sea', 'seas', 'seamos', 'seáis', 'sean', 'seré', 'serás', 'será', 'seremos', 'seréis', 'serán', 'sería', 'serías', 'seríamos', 'seríais', 'serían', 'era', 'eras', 'éramos', 'erais', 'eran', 'fui', 'fuiste', 'fue', 'fuimos', 'fuisteis', 'fueron', 'fuera', 'fueras', 'fuéramos', 'fuerais', 'fueran', 'fuese', 'fueses', 'fuésemos', 'fueseis', 'fuesen', 'sintiendo', 'sentido', 'sentida', 'sentidos', 'sentidas', 'siente', 'sentid', 'tengo', 'tienes', 'tiene', 'tenemos', 'tenéis', 'tienen', 'tenga', 'tengas', 'tengamos', 'tengáis', 'tengan', 'tendré', 'tendrás', 'tendrá', 'tendremos', 'tendréis', 'tendrán', 'tendría', 'tendrías', 'tendríamos', 'tendríais', 'tendrían', 'tenía', 'tenías', 'teníamos', 'teníais', 'tenían', 'tuve', 'tuviste', 'tuvo', 'tuvimos', 'tuvisteis', 'tuvieron', 'tuviera', 'tuvieras', 'tuviéramos', 'tuvierais', 'tuvieran', 'tuviese', 'tuvieses', 'tuviésemos', 'tuvieseis', 'tuviesen', 'teniendo', 'tenido', 'tenida', 'tenidos', 'tenidas', 'tened', 'rt', 'aun', 'oe']\n",
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~¿\n"
     ]
    }
   ],
   "source": [
    "stop_words = stopwords.words('spanish')\n",
    "stop_words.extend([\"rt\", \"aun\", \"oe\"])\n",
    "exclude = string.punctuation\n",
    "exclude = exclude + \"¿\"\n",
    "\n",
    "lemma = SnowballStemmer('spanish')\n",
    "\n",
    "print(stop_words)\n",
    "print(exclude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "##def remove_number(list_text):\n",
    "##    return ''.join([i for i in text if not i.isdigit()])\n",
    "\n",
    "def remove_three_dots(list_text):\n",
    "    return [re.sub(r\"[a-zA-Z]+(\\……|\\…)$\", \" \", texto) for texto in list_text]\n",
    "\n",
    "def remove_url(list_text):\n",
    "    return [re.sub(r\"http\\S+\", \"\", texto).strip() for texto in list_text]\n",
    "\n",
    "def remove_breakline(list_text):\n",
    "    return [re.sub('\\s+', ' ', texto) for texto in list_text]\n",
    "\n",
    "def remove_single_quotes(list_text):\n",
    "    return [re.sub(\"\\'\", \"\", texto) for texto in list_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Como cuando ahora también tiene que prepararte psicológicamente para el torneo #marcianogaming #PUBGMOBILE… https://t.co/buM1Bn6dqE', 'Sres. @AsambleaEcuador no arriesguen más la salud de los jóvenes mediante el uso “medicinal” de marihuana. Sin estu… https://t.co/u3DKINYIcf', 'Comencemos esta experiencia!! #psicologosenelmundo #psicologovenezolano #reclutamientoyseleccion… https://t.co/EGMyHDcGij', '@galarzaramiro1 @AdrianPalacioJ @VillaFernando_ Debería pedirle el  crédito a AP; tienen para darnos fácil unos 20B… https://t.co/trwLssbhfC']\n"
     ]
    }
   ],
   "source": [
    "data = data_db.texto.values.tolist()\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['como', 'cuando', 'ahora', 'tambien', 'tiene', 'que', 'prepararte', 'para', 'el', 'torneo', 'marcianogaming'], ['sres', 'asambleaecuador', 'no', 'arriesguen', 'mas', 'la', 'salud', 'de', 'los', 'jovenes', 'mediante', 'el', 'uso', 'medicinal', 'de', 'marihuana', 'sin'], ['comencemos', 'esta', 'experiencia'], ['galarzaramiro', 'adrianpalacioj', 'villafernando_', 'deberia', 'pedirle', 'el', 'credito', 'ap', 'tienen', 'para', 'darnos', 'facil', 'unos']]\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "\n",
    "txt_free_url = remove_url(data)\n",
    "txt_free_threedot = remove_three_dots(txt_free_url)\n",
    "txt_free_breakline = remove_breakline(txt_free_threedot)\n",
    "txt_free_singlequotes = remove_single_quotes(txt_free_breakline)\n",
    "\n",
    "def texto_a_palabras(texto:str):\n",
    "    for sentencia in texto:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentencia), deacc=True))\n",
    "        \n",
    "data_palabras = list(texto_a_palabras(txt_free_singlequotes))\n",
    "\n",
    "print(data_palabras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jkn/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
     ]
    }
   ],
   "source": [
    "bigram = gensim.models.Phrases(data_palabras, min_count=5, threshold=100)\n",
    "trigram = gensim.models.Phrases(bigram[data_palabras], threshold=100)\n",
    "\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['comencemos', 'esta', 'experiencia']\n"
     ]
    }
   ],
   "source": [
    "print(bigram_mod[data_palabras[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['ahora', 'tambien', 'prepararte', 'tornear', 'marcianogaming'], ['sres', 'asambleaecuador', 'arriesgar', 'mas', 'salud', 'jovenes', 'usar', 'medicinal', 'marihuana'], ['comenzar', 'experiencia'], ['galarzaramiro', 'adrianpalacioj', 'villafernando', '_', 'deberia', 'pedirle', 'credito', 'ap', 'darnos', 'facil']]\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "# python -m spacy download es\n",
    "\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in gensim.utils.simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "\n",
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out\n",
    "\n",
    "data_words_nostops = remove_stopwords(data_palabras)\n",
    "data_words_bigrams = make_bigrams(data_words_nostops)\n",
    "nlp = spacy.load('es', disable=['parser', 'ner'])\n",
    "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "print(data_lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora\n",
    " \n",
    "diccionario = corpora.Dictionary(data_lemmatized)\n",
    "#Corpus\n",
    "texto = data_lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['comencemos', 'experiencia']\n",
      "[(14, 1), (15, 1)]\n"
     ]
    }
   ],
   "source": [
    "corpus = [diccionario.doc2bow(doc) for doc in texto]\n",
    "\n",
    "print(data_words_bigrams[2])\n",
    "print(corpus[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sres', 'asambleaecuador', 'arriesguen', 'mas', 'salud', 'jovenes', 'mediante', 'uso', 'medicinal', 'marihuana']\n",
      "[(5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1)]\n"
     ]
    }
   ],
   "source": [
    "print (data_words_bigrams[1])\n",
    "print (corpus[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('ahora', 1),\n",
       "  ('marcianogaming', 1),\n",
       "  ('prepararte', 1),\n",
       "  ('tambien', 1),\n",
       "  ('tornear', 1)],\n",
       " [('arriesgar', 1),\n",
       "  ('asambleaecuador', 1),\n",
       "  ('jovenes', 1),\n",
       "  ('marihuana', 1),\n",
       "  ('mas', 1),\n",
       "  ('medicinal', 1),\n",
       "  ('salud', 1),\n",
       "  ('sres', 1),\n",
       "  ('usar', 1)],\n",
       " [('comenzar', 1), ('experiencia', 1)]]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[(diccionario[id], freq) for id, freq in cp] for cp in corpus[0:3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n"
     ]
    }
   ],
   "source": [
    "print(len(list(diccionario.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correr y entrenar el modelo LDA sobre la matriz de términos.\n",
    "lda_model = gensim.models.LdaModel(corpus,\n",
    "                                   num_topics=20,\n",
    "                                   id2word = diccionario,\n",
    "                                   random_state=100,\n",
    "                                   passes=10,\n",
    "                                   update_every=1,\n",
    "                                   chunksize=100,\n",
    "                                   alpha='auto',\n",
    "                                   per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 Word: 0.038*\"credito\" + 0.038*\"deberia\" + 0.038*\"_\" + 0.038*\"adrianpalacioj\" + 0.038*\"ap\" + 0.038*\"comenzar\" + 0.038*\"darnos\" + 0.038*\"pedirle\" + 0.038*\"galarzaramiro\" + 0.038*\"sres\"\n",
      "\n",
      "Topic: 1 Word: 0.038*\"credito\" + 0.038*\"deberia\" + 0.038*\"_\" + 0.038*\"adrianpalacioj\" + 0.038*\"ap\" + 0.038*\"comenzar\" + 0.038*\"darnos\" + 0.038*\"pedirle\" + 0.038*\"galarzaramiro\" + 0.038*\"sres\"\n",
      "\n",
      "Topic: 2 Word: 0.038*\"credito\" + 0.038*\"deberia\" + 0.038*\"_\" + 0.038*\"adrianpalacioj\" + 0.038*\"ap\" + 0.038*\"comenzar\" + 0.038*\"darnos\" + 0.038*\"pedirle\" + 0.038*\"galarzaramiro\" + 0.038*\"sres\"\n",
      "\n",
      "Topic: 3 Word: 0.038*\"credito\" + 0.038*\"deberia\" + 0.038*\"_\" + 0.038*\"adrianpalacioj\" + 0.038*\"ap\" + 0.038*\"comenzar\" + 0.038*\"darnos\" + 0.038*\"pedirle\" + 0.038*\"galarzaramiro\" + 0.038*\"sres\"\n",
      "\n",
      "Topic: 4 Word: 0.038*\"credito\" + 0.038*\"deberia\" + 0.038*\"_\" + 0.038*\"adrianpalacioj\" + 0.038*\"ap\" + 0.038*\"comenzar\" + 0.038*\"darnos\" + 0.038*\"pedirle\" + 0.038*\"galarzaramiro\" + 0.038*\"sres\"\n",
      "\n",
      "Topic: 5 Word: 0.038*\"credito\" + 0.038*\"deberia\" + 0.038*\"_\" + 0.038*\"adrianpalacioj\" + 0.038*\"ap\" + 0.038*\"comenzar\" + 0.038*\"darnos\" + 0.038*\"pedirle\" + 0.038*\"galarzaramiro\" + 0.038*\"sres\"\n",
      "\n",
      "Topic: 6 Word: 0.038*\"credito\" + 0.038*\"deberia\" + 0.038*\"_\" + 0.038*\"adrianpalacioj\" + 0.038*\"ap\" + 0.038*\"comenzar\" + 0.038*\"darnos\" + 0.038*\"pedirle\" + 0.038*\"galarzaramiro\" + 0.038*\"sres\"\n",
      "\n",
      "Topic: 7 Word: 0.038*\"credito\" + 0.038*\"deberia\" + 0.038*\"_\" + 0.038*\"adrianpalacioj\" + 0.038*\"ap\" + 0.038*\"comenzar\" + 0.038*\"darnos\" + 0.038*\"pedirle\" + 0.038*\"galarzaramiro\" + 0.038*\"sres\"\n",
      "\n",
      "Topic: 8 Word: 0.038*\"credito\" + 0.038*\"deberia\" + 0.038*\"_\" + 0.038*\"adrianpalacioj\" + 0.038*\"ap\" + 0.038*\"comenzar\" + 0.038*\"darnos\" + 0.038*\"pedirle\" + 0.038*\"galarzaramiro\" + 0.038*\"sres\"\n",
      "\n",
      "Topic: 9 Word: 0.318*\"experiencia\" + 0.318*\"comenzar\" + 0.015*\"ap\" + 0.015*\"darnos\" + 0.015*\"_\" + 0.015*\"adrianpalacioj\" + 0.015*\"pedirle\" + 0.015*\"credito\" + 0.015*\"sres\" + 0.015*\"galarzaramiro\"\n",
      "\n",
      "Topic: 10 Word: 0.038*\"credito\" + 0.038*\"deberia\" + 0.038*\"_\" + 0.038*\"adrianpalacioj\" + 0.038*\"ap\" + 0.038*\"comenzar\" + 0.038*\"darnos\" + 0.038*\"pedirle\" + 0.038*\"galarzaramiro\" + 0.038*\"sres\"\n",
      "\n",
      "Topic: 11 Word: 0.038*\"credito\" + 0.038*\"deberia\" + 0.038*\"_\" + 0.038*\"adrianpalacioj\" + 0.038*\"ap\" + 0.038*\"comenzar\" + 0.038*\"darnos\" + 0.038*\"pedirle\" + 0.038*\"galarzaramiro\" + 0.038*\"sres\"\n",
      "\n",
      "Topic: 12 Word: 0.038*\"credito\" + 0.038*\"deberia\" + 0.038*\"_\" + 0.038*\"adrianpalacioj\" + 0.038*\"ap\" + 0.038*\"comenzar\" + 0.038*\"darnos\" + 0.038*\"pedirle\" + 0.038*\"galarzaramiro\" + 0.038*\"sres\"\n",
      "\n",
      "Topic: 13 Word: 0.102*\"asambleaecuador\" + 0.102*\"arriesgar\" + 0.102*\"mas\" + 0.102*\"marihuana\" + 0.102*\"sres\" + 0.102*\"salud\" + 0.102*\"usar\" + 0.102*\"jovenes\" + 0.102*\"medicinal\" + 0.005*\"deberia\"\n",
      "\n",
      "Topic: 14 Word: 0.093*\"_\" + 0.093*\"deberia\" + 0.093*\"pedirle\" + 0.093*\"galarzaramiro\" + 0.093*\"facil\" + 0.093*\"villafernando\" + 0.093*\"darnos\" + 0.093*\"credito\" + 0.093*\"ap\" + 0.093*\"adrianpalacioj\"\n",
      "\n",
      "Topic: 15 Word: 0.038*\"credito\" + 0.038*\"deberia\" + 0.038*\"_\" + 0.038*\"adrianpalacioj\" + 0.038*\"ap\" + 0.038*\"comenzar\" + 0.038*\"darnos\" + 0.038*\"pedirle\" + 0.038*\"galarzaramiro\" + 0.038*\"sres\"\n",
      "\n",
      "Topic: 16 Word: 0.038*\"credito\" + 0.038*\"deberia\" + 0.038*\"_\" + 0.038*\"adrianpalacioj\" + 0.038*\"ap\" + 0.038*\"comenzar\" + 0.038*\"darnos\" + 0.038*\"pedirle\" + 0.038*\"galarzaramiro\" + 0.038*\"sres\"\n",
      "\n",
      "Topic: 17 Word: 0.038*\"credito\" + 0.038*\"deberia\" + 0.038*\"_\" + 0.038*\"adrianpalacioj\" + 0.038*\"ap\" + 0.038*\"comenzar\" + 0.038*\"darnos\" + 0.038*\"pedirle\" + 0.038*\"galarzaramiro\" + 0.038*\"sres\"\n",
      "\n",
      "Topic: 18 Word: 0.038*\"credito\" + 0.038*\"deberia\" + 0.038*\"_\" + 0.038*\"adrianpalacioj\" + 0.038*\"ap\" + 0.038*\"comenzar\" + 0.038*\"darnos\" + 0.038*\"pedirle\" + 0.038*\"galarzaramiro\" + 0.038*\"sres\"\n",
      "\n",
      "Topic: 19 Word: 0.167*\"prepararte\" + 0.167*\"tambien\" + 0.167*\"tornear\" + 0.167*\"marcianogaming\" + 0.167*\"ahora\" + 0.008*\"credito\" + 0.008*\"galarzaramiro\" + 0.008*\"ap\" + 0.008*\"_\" + 0.008*\"darnos\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in lda_model.print_topics():\n",
    "    print('Topic: {} Word: {}\\n'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Object of type 'complex' is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    339\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m             \u001b[0;31m# Finally look for special method names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pyLDAvis/_display.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(data, kwds)\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[0mformatter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformatters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text/html'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m     formatter.for_type(PreparedData,\n\u001b[0;32m--> 313\u001b[0;31m                        lambda data, kwds=kwargs: prepared_data_to_html(data, **kwds))\n\u001b[0m\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pyLDAvis/_display.py\u001b[0m in \u001b[0;36mprepared_data_to_html\u001b[0;34m(data, d3_url, ldavis_url, ldavis_css_url, template_type, visid, use_http)\u001b[0m\n\u001b[1;32m    176\u001b[0m                            \u001b[0md3_url\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0md3_url\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m                            \u001b[0mldavis_url\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mldavis_url\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m                            \u001b[0mvis_json\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m                            ldavis_css_url=ldavis_css_url)\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pyLDAvis/_prepare.py\u001b[0m in \u001b[0;36mto_json\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mto_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNumPyEncoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/json/__init__.py\u001b[0m in \u001b[0;36mdumps\u001b[0;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0mcheck_circular\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_circular\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_nan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0mseparators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseparators\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m         **kw).encode(obj)\n\u001b[0m\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/json/encoder.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;31m# exceptions aren't as detailed.  The list call should be roughly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;31m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_one_shot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/json/encoder.py\u001b[0m in \u001b[0;36miterencode\u001b[0;34m(self, o, _one_shot)\u001b[0m\n\u001b[1;32m    255\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey_separator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem_separator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m                 self.skipkeys, _one_shot)\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m def _make_iterencode(markers, _default, _encoder, _indent, _floatstr,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pyLDAvis/utils.py\u001b[0m in \u001b[0;36mdefault\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mJSONEncoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/json/encoder.py\u001b[0m in \u001b[0;36mdefault\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \"\"\"\n\u001b[1;32m    179\u001b[0m         raise TypeError(\"Object of type '%s' is not JSON serializable\" %\n\u001b[0;32m--> 180\u001b[0;31m                         o.__class__.__name__)\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Object of type 'complex' is not JSON serializable"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PreparedData(topic_coordinates=                                 x                            y  topics  \\\n",
       "topic                                                                     \n",
       "14        (0.24402724830110306+0j)    (-0.11175796752687901+0j)       1   \n",
       "13       (-0.24729437946628047+0j)    (-0.11513314952745307+0j)       2   \n",
       "19      (-0.004254637008152192+0j)      (0.2747618833391872+0j)       3   \n",
       "9       (0.0022320934659234397+0j)    (-0.00786389116286979+0j)       4   \n",
       "15     (0.00033060466921291297+0j)  (-0.0025004296951239968+0j)       5   \n",
       "16     (0.00033060466921292197+0j)  (-0.0025004296951240314+0j)       6   \n",
       "17      (0.0003306046692129093+0j)  (-0.0025004296951240327+0j)       7   \n",
       "12       (0.000330604669212914+0j)   (-0.002500429695124042+0j)       8   \n",
       "11     (0.00033060466921289367+0j)   (-0.002500429695124073+0j)       9   \n",
       "10      (0.0003306046692129074+0j)   (-0.002500429695124074+0j)      10   \n",
       "18      (0.0003306046692129078+0j)   (-0.002500429695124086+0j)      11   \n",
       "8       (0.0003306046692128983+0j)   (-0.002500429695124089+0j)      12   \n",
       "7      (0.00033060466921291113+0j)   (-0.002500429695124093+0j)      13   \n",
       "6       (0.0003306046692129008+0j)   (-0.002500429695124098+0j)      14   \n",
       "5       (0.0003306046692129284+0j)  (-0.0025004296951240974+0j)      15   \n",
       "4       (0.0003306046692129066+0j)   (-0.002500429695124096+0j)      16   \n",
       "3      (0.00033060466921290104+0j)  (-0.0025004296951241056+0j)      17   \n",
       "2       (0.0003306046692129062+0j)  (-0.0025004296951241286+0j)      18   \n",
       "1      (0.00033060466921288977+0j)  (-0.0025004296951240514+0j)      19   \n",
       "0       (0.0003306046692128984+0j)   (-0.002500429695124017+0j)      20   \n",
       "\n",
       "       cluster       Freq  \n",
       "topic                      \n",
       "14           1  36.677616  \n",
       "13           1  32.848827  \n",
       "19           1  17.606556  \n",
       "9            1   6.479620  \n",
       "15           1   0.399211  \n",
       "16           1   0.399211  \n",
       "17           1   0.399211  \n",
       "12           1   0.399211  \n",
       "11           1   0.399211  \n",
       "10           1   0.399211  \n",
       "18           1   0.399211  \n",
       "8            1   0.399211  \n",
       "7            1   0.399211  \n",
       "6            1   0.399211  \n",
       "5            1   0.399211  \n",
       "4            1   0.399211  \n",
       "3            1   0.399211  \n",
       "2            1   0.399211  \n",
       "1            1   0.399211  \n",
       "0            1   0.399211  , topic_info=     Category      Freq             Term     Total  loglift  logprob\n",
       "term                                                                \n",
       "25    Default  1.000000    villafernando  1.000000  26.0000  26.0000\n",
       "24    Default  1.000000          pedirle  1.000000  25.0000  25.0000\n",
       "23    Default  1.000000    galarzaramiro  1.000000  24.0000  24.0000\n",
       "22    Default  1.000000            facil  1.000000  23.0000  23.0000\n",
       "21    Default  1.000000          deberia  1.000000  22.0000  22.0000\n",
       "20    Default  1.000000           darnos  1.000000  21.0000  21.0000\n",
       "19    Default  1.000000          credito  1.000000  20.0000  20.0000\n",
       "18    Default  1.000000               ap  1.000000  19.0000  19.0000\n",
       "17    Default  1.000000   adrianpalacioj  1.000000  18.0000  18.0000\n",
       "16    Default  1.000000                _  1.000000  17.0000  17.0000\n",
       "12    Default  1.000000             sres  1.000000  16.0000  16.0000\n",
       "13    Default  1.000000             usar  1.000000  15.0000  15.0000\n",
       "11    Default  1.000000            salud  1.000000  14.0000  14.0000\n",
       "10    Default  1.000000        medicinal  1.000000  13.0000  13.0000\n",
       "9     Default  1.000000              mas  1.000000  12.0000  12.0000\n",
       "8     Default  1.000000        marihuana  1.000000  11.0000  11.0000\n",
       "7     Default  1.000000          jovenes  1.000000  10.0000  10.0000\n",
       "6     Default  1.000000  asambleaecuador  1.000000   9.0000   9.0000\n",
       "5     Default  1.000000        arriesgar  1.000000   8.0000   8.0000\n",
       "1     Default  0.000000   marcianogaming  0.000000   7.0000   7.0000\n",
       "4     Default  0.000000          tornear  0.000000   6.0000   6.0000\n",
       "3     Default  0.000000          tambien  0.000000   5.0000   5.0000\n",
       "2     Default  0.000000       prepararte  0.000000   4.0000   4.0000\n",
       "0     Default  0.000000            ahora  0.000000   3.0000   3.0000\n",
       "14    Default  0.000000         comenzar  0.000000   2.0000   2.0000\n",
       "15    Default  0.000000      experiencia  0.000000   1.0000   1.0000\n",
       "25     Topic1  0.886105    villafernando  1.053295   0.8302  -2.3760\n",
       "23     Topic1  0.886105    galarzaramiro  1.053295   0.8302  -2.3760\n",
       "22     Topic1  0.886105            facil  1.053295   0.8302  -2.3760\n",
       "21     Topic1  0.886105          deberia  1.053295   0.8302  -2.3760\n",
       "...       ...       ...              ...       ...      ...      ...\n",
       "21    Topic19  0.003992          deberia  1.053295  -0.0519  -3.2581\n",
       "22    Topic19  0.003992            facil  1.053295  -0.0519  -3.2581\n",
       "23    Topic19  0.003992    galarzaramiro  1.053295  -0.0519  -3.2581\n",
       "25    Topic19  0.003992    villafernando  1.053295  -0.0519  -3.2581\n",
       "15    Topic20  0.003992      experiencia  0.719902   0.3286  -3.2581\n",
       "14    Topic20  0.003992         comenzar  0.719902   0.3286  -3.2581\n",
       "0     Topic20  0.003992            ahora  0.936006   0.0661  -3.2581\n",
       "1     Topic20  0.003992   marcianogaming  0.936006   0.0661  -3.2581\n",
       "2     Topic20  0.003992       prepararte  0.936006   0.0661  -3.2581\n",
       "3     Topic20  0.003992          tambien  0.936006   0.0661  -3.2581\n",
       "4     Topic20  0.003992          tornear  0.936006   0.0661  -3.2581\n",
       "11    Topic20  0.003992            salud  1.038580  -0.0379  -3.2581\n",
       "5     Topic20  0.003992        arriesgar  1.038580  -0.0379  -3.2581\n",
       "6     Topic20  0.003992  asambleaecuador  1.038580  -0.0379  -3.2581\n",
       "7     Topic20  0.003992          jovenes  1.038580  -0.0379  -3.2581\n",
       "8     Topic20  0.003992        marihuana  1.038580  -0.0379  -3.2581\n",
       "9     Topic20  0.003992              mas  1.038580  -0.0379  -3.2581\n",
       "10    Topic20  0.003992        medicinal  1.038580  -0.0379  -3.2581\n",
       "12    Topic20  0.003992             sres  1.038580  -0.0379  -3.2581\n",
       "13    Topic20  0.003992             usar  1.038580  -0.0379  -3.2581\n",
       "24    Topic20  0.003992          pedirle  1.053295  -0.0519  -3.2581\n",
       "16    Topic20  0.003992                _  1.053295  -0.0519  -3.2581\n",
       "17    Topic20  0.003992   adrianpalacioj  1.053295  -0.0519  -3.2581\n",
       "18    Topic20  0.003992               ap  1.053295  -0.0519  -3.2581\n",
       "19    Topic20  0.003992          credito  1.053295  -0.0519  -3.2581\n",
       "20    Topic20  0.003992           darnos  1.053295  -0.0519  -3.2581\n",
       "21    Topic20  0.003992          deberia  1.053295  -0.0519  -3.2581\n",
       "22    Topic20  0.003992            facil  1.053295  -0.0519  -3.2581\n",
       "23    Topic20  0.003992    galarzaramiro  1.053295  -0.0519  -3.2581\n",
       "25    Topic20  0.003992    villafernando  1.053295  -0.0519  -3.2581\n",
       "\n",
       "[546 rows x 6 columns], token_table=      Topic      Freq             Term\n",
       "term                                  \n",
       "16        1  0.949401                _\n",
       "17        1  0.949401   adrianpalacioj\n",
       "0         3  1.068369            ahora\n",
       "18        1  0.949401               ap\n",
       "5         2  0.962853        arriesgar\n",
       "6         2  0.962853  asambleaecuador\n",
       "14        4  1.389078         comenzar\n",
       "19        1  0.949401          credito\n",
       "20        1  0.949401           darnos\n",
       "21        1  0.949401          deberia\n",
       "15        4  1.389078      experiencia\n",
       "22        1  0.949401            facil\n",
       "23        1  0.949401    galarzaramiro\n",
       "7         2  0.962853          jovenes\n",
       "1         3  1.068369   marcianogaming\n",
       "8         2  0.962853        marihuana\n",
       "9         2  0.962853              mas\n",
       "10        2  0.962853        medicinal\n",
       "24        1  0.949401          pedirle\n",
       "2         3  1.068369       prepararte\n",
       "11        2  0.962853            salud\n",
       "12        2  0.962853             sres\n",
       "3         3  1.068369          tambien\n",
       "4         3  1.068369          tornear\n",
       "13        2  0.962853             usar\n",
       "25        1  0.949401    villafernando, R=26, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[15, 14, 20, 10, 16, 17, 18, 13, 12, 11, 19, 9, 8, 7, 6, 5, 4, 3, 2, 1])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pip install pyLDAvis\n",
    "\n",
    "import warnings\n",
    "import pyLDAvis.gensim\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(lda_model,corpus,diccionario)\n",
    "vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
